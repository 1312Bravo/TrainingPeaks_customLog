{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309f9c2a",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "326c7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")  \n",
    "from src import config\n",
    "from src import help_functions as hf\n",
    "\n",
    "# Configs\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d1468",
   "metadata": {},
   "source": [
    "### Import and quick check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a67892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data about:\n",
      "-----------------------------------------------------\n",
      "Todays date: 2025-08-23\n",
      "Date range: 2024-09-13 to 2025-08-22\n",
      "Duplicated rows = 0\n",
      "Missing dates = []\n",
      "\n",
      "Different activities and their counts:\n",
      "-------------------------------------\n",
      "Trail Running ~> 276.44 hours (149 act.)\n",
      "Road Biking ~> 80.82 hours (33 act.)\n",
      "Running ~> 78.25 hours (76 act.)\n",
      "Indoor Biking ~> 71.04 hours (51 act.)\n",
      "Mountain Biking ~> 16.99 hours (9 act.)\n",
      "Hiking ~> 15.35 hours (6 act.)\n",
      "Road biking ~> 3.74 hours (2 act.)\n",
      "Lap Swimming ~> 0.21 hours (1 act.)\n"
     ]
    }
   ],
   "source": [
    "# Import and quick check Training data \n",
    "googleDrive_client = gspread.authorize(config.DRIVE_CREDENTIALS)\n",
    "training_data, _ = hf.import_google_sheet(googleDrive_client=googleDrive_client, filename=config.DRIVE_TP_LOG_FILENAMES[0], sheet_index=0)\n",
    "\n",
    "# \"Clean\" data\n",
    "for col in training_data.columns:\n",
    "    try:\n",
    "        training_data[col] = training_data[col].apply(hf.safe_convert_to_numeric)\n",
    "    except ValueError:\n",
    "        pass \n",
    "\n",
    "# Date & Datetime\n",
    "training_data[\"Date\"] = pd.to_datetime(training_data[[\"Year\", \"Month\", \"Day\"]]).dt.date\n",
    "training_data[\"Datetime\"] = pd.to_datetime(training_data[[\"Year\", \"Month\", \"Day\"]])\n",
    "training_data = training_data.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "# About\n",
    "print(\"Training data about:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Todays date: {}\".format(datetime.datetime.today().date()))\n",
    "print(\"Date range: {} to {}\".format(training_data[\"Date\"].min(), training_data[\"Date\"].max()))\n",
    "print(\"Duplicated rows = {}\".format(training_data[training_data.duplicated(keep=False)].shape[0]))\n",
    "print(\"Missing dates = {}\".format([d for d in pd.date_range(start=training_data[\"Date\"].min(), end=training_data[\"Date\"].max()).date if d not in training_data[\"Date\"].values]))\n",
    "\n",
    "print(\"\\nDifferent activities and their counts:\")\n",
    "print(\"-------------------------------------\")\n",
    "activities_count_time = (\n",
    "    training_data\n",
    "    .groupby(\"Activity type\")[[\"Duration [h]\"]]\n",
    "    .agg(\n",
    "        count=(\"Duration [h]\", \"count\"),\n",
    "        total_duration=(\"Duration [h]\", \"sum\")\n",
    "        )\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"total_duration\", ascending=False)\n",
    "    )\n",
    "\n",
    "for _, row in activities_count_time.iterrows():\n",
    "    print(\"{} ~> {:.2f} hours ({} act.)\".format(row[\"Activity type\"], row[\"total_duration\"], row[\"count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5839ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily data about:\n",
      "-----------------------------------------------------\n",
      "Todays date: 2025-08-23\n",
      "Date range: 2024-04-15 to 2025-08-22\n",
      "Duplicated rows = 0\n",
      "Missing dates = []\n"
     ]
    }
   ],
   "source": [
    "# Import and quick check Daily data\n",
    "googleDrive_client = gspread.authorize(config.DRIVE_CREDENTIALS)\n",
    "daily_data, _ = hf.import_google_sheet(googleDrive_client=googleDrive_client, filename=config.DRIVE_TP_LOG_FILENAMES[1], sheet_index=0)\n",
    "\n",
    "# \"Clean\" data\n",
    "for col in daily_data.columns:\n",
    "    try:\n",
    "        daily_data[col] = daily_data[col].apply(hf.safe_convert_to_numeric)\n",
    "    except ValueError:\n",
    "        pass \n",
    "\n",
    "# Date & Datetime\n",
    "daily_data[\"Date\"] = pd.to_datetime(daily_data[[\"Year\", \"Month\", \"Day\"]]).dt.date\n",
    "daily_data[\"Datetime\"] = pd.to_datetime(daily_data[[\"Year\", \"Month\", \"Day\"]])\n",
    "daily_data = daily_data.sort_values(by=\"Date\").reset_index(drop=True)\n",
    "\n",
    "# About\n",
    "print(\"Daily data about:\")\n",
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Todays date: {}\".format(datetime.datetime.today().date()))\n",
    "print(\"Date range: {} to {}\".format(daily_data[\"Date\"].min(), daily_data[\"Date\"].max()))\n",
    "print(\"Duplicated rows = {}\".format(daily_data[daily_data.duplicated(keep=False)].shape[0]))\n",
    "print(\"Missing dates = {}\".format([d for d in pd.date_range(start=daily_data[\"Date\"].min(), end=daily_data[\"Date\"].max()).date if d not in daily_data[\"Date\"].values]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39182a",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Data preparation:\n",
    "- We will take all activities into account regardless if it was real training or not (including Hiking and Swimming or cycling with my girlfriend).\n",
    "- Given the above, and since in principle I only have one \"real\" workout per day, we will calculate the total training load in the day, so that each sample is one day. This also solves the problem of the \"not real\" workouts mentioned above. However, if we could have more serious workouts in the day, we would consider each sample one workout and in order not to distort the TL data, we would want to discard everything that is not a real workout.\n",
    "\n",
    "Formal definitions:\n",
    "- $TL_t$ - Training load of the day t\n",
    "- $TL_{\\text{avg},t} = \\frac{1}{n} \\sum_{i=1}^{n} TL_{t}$ - recent Average Load over n days\n",
    "- $TL_{\\text{max},t} = \\max(TL_{t-1}, TL_{t-2}, \\dots, TL_{t-n})$ - recent peak load over n sessions\n",
    "- $RTL_{\\text{avg},t} = \\frac{TL_t}{TL_{\\text{avg},t}}$ - relative to recent average\n",
    "- $RTL_{\\text{peak},t} = \\frac{TL_t}{TL_{\\text{max},t}}$ - relative to recent peak\n",
    "- $RTL^*_t = \\alpha \\cdot RTL_{\\text{avg},t} + (1 - \\alpha) \\cdot RTL_{\\text{peak},t} \\quad 0 \\le \\alpha \\le 1$ - Composite Metric\n",
    "\n",
    "Notes:\n",
    "- Using a rolling average (TL_avg) or rolling peak (TL_max) captures your recent training state. It contextualizes today’s session: a 300 TRIMP session might be heavy for someone who has only done 200 TRIMP sessions recently, but normal for someone consistently doing 400.\n",
    "- RTL_avg shows relative load compared to baseline adaptation (sustained training).\n",
    "- RTL_peak shows relative load compared to recent maximum stress, highlighting spikes that may be riskier.\n",
    "- Combining them with a weight α gives a balanced view, accounting for both consistency and acute stress.\n",
    "\n",
    "Potential improvements:\n",
    "- Instead of a fixed n sessions, you could weight recent sessions more (exponential moving average): $TL_{\\text{EMA},t} = \\frac{\\sum_{i=1}^{n} TL_{t-i} \\cdot \\lambda^{i-1}}{\\sum_{i=1}^{n} \\lambda^{i-1}}, \\quad 0 < \\lambda \\le 1$.\n",
    "- Nonlinear combination of average and peak. Sometimes spikes should count more than their linear weight: $RTL^*_t = \\left(RTL_{\\text{avg},t}\\right)^\\beta \\cdot \\left(RTL_{\\text{peak},t}\\right)^{1-\\beta}, \\quad \\beta \\in [0,1]$.\n",
    "- Multi-metric composite. Instead of using just TL, we could combine distance, duration, and intensity into a single RTL vector: $\\mathbf{RTL}_t = [RTL_{TL,t}, RTL_{D,t}, RTL_{T,t}, RTL_{HR,t}]$\n",
    "- Fatigue / readiness adjustment. Relative load could be normalized by recovery metrics (HRV, sleep, resting HR): $TL_{\\text{adj},t} = \\frac{RTL_t}{1 + f(\\text{HRV}_t, \\text{rest}_t)}$\n",
    "\n",
    "Benefits:\n",
    "- Captures context: It tells you if today’s session is heavy relative to your current state.\n",
    "- Avoids overtraining risk: spikes above recent peak are immediately visible.\n",
    "- Enables better training decisions: you can plan lighter or heavier sessions relative to recent load.\n",
    "- Makes metrics comparable across athletes or periods by using ratios rather than absolute values.\n",
    "\n",
    "Additional: Using RTL for smarter periodization\n",
    "- The classic idea: you don’t just train hard every day. You want to match training stress to recent load and recovery, which is essentially auto-regulated periodization.\n",
    "- Low recent load - higher intensity is safe - RTL will be below 1, signaling that a spike is acceptable.\n",
    "- High recent load - reduce intensity - If RTL is already above 1 (or near peak), adding a hard session risks overtraining or injury.\n",
    "- Goal: structured variation - microcycle approach. \n",
    "- This is where the above potential improvements help: \n",
    "    - Exponential weighting for recent load - metric is sensitive to very recent fatigue.\n",
    "    - Nonlinear combination of avg and peak - Spikes in load are highlighted more strongly.\n",
    "    - Multi-metric RTL - You might have a “distance-heavy” day but low intensity, or vice versa. (High RTL_distance - limit long runs & High RTL_HR - limit high-intensity intervals).\n",
    "    - Recovery-adjusted RTL - You can have a “hard” day only if both recent load is low and body is ready.\n",
    "\n",
    "$$\n",
    "\\text{Next session intensity} =\n",
    "\\begin{cases} \n",
    "\\text{Hard}, & \\text{if } RTL_{\\text{adj}} < 0.8 \\\\[2mm]\n",
    "\\text{Moderate}, & \\text{if } 0.8 \\le RTL_{\\text{adj}} \\le 1.2 \\\\[1mm]\n",
    "\\text{Easy / Recovery}, & \\text{if } RTL_{\\text{adj}} > 1.2\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Youu can tune the thresholds based on athlete type, sport, or training phase. This produces an adaptive low-low-hard pattern automatically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
